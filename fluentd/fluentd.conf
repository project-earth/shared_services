<source>
    @type tail
    path /opt/dat/logs/*/query.sql.log
    pos_file /opt/dat/fluentd/sql_query_log_pos
    read_from_head true
    path_key log_path
    tag sql
    <parse>
        @type multiline
        format_firstline /# User@Host: .*/
        format1 /# Thread_id: .*/
        format2 /# Query_time: (?<query_time>[^ ]+) .*/
        format3 /# Rows_affected: .*/
        format4 /SET timestamp=(?<@timestamp>[0-9]+);\n(?<message>.*)/
    </parse>
</source>

<source>
    @type tail
    path /opt/dat/logs/*/*.py.log
    pos_file /opt/dat/fluentd/service_log_pos
    read_from_head true
    path_key log_path
    tag service
    <parse>
        @type multiline
        format_firstline /\([T0-9-+:]+\)/
        format1 /\((?<@timestamp>[T0-9-+:]+)\)\[(?<level>[A-Z]+)\]: (?<message>.*)/
    </parse>
</source>

<filter sql>
    @type record_transformer
    enable_ruby
    <record>
        @timestamp ${Time.at(record["@timestamp"].to_i).strftime("%Y-%m-%dT%H:%M:%S+00:00")}
        log_path ${record["log_path"]}
        container_id ${record["log_path"].split("/")[4]}
        file_name ${record["log_path"].split("/")[-1]}
        message ${record["message"].gsub(/# Time: .*/m,"").strip}
    </record>
</filter>

<filter service>
    @type record_transformer
    enable_ruby
    <record>
        @timestamp ${record["@timestamp"].gsub(" ","::")}
        log_path ${record["log_path"]}
        container_id ${record["log_path"].split("/")[4]}
        file_name ${record["log_path"].split("/")[-1]}
    </record>
</filter>

<match **>
    @type elasticsearch
    host localhost
    port $ELASTICSEARCH_PORT
    index_name logging
</match>
